{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80e18348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random as r\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#####################\n",
    "##### FUNCTIONS #####\n",
    "#####################\n",
    "\n",
    "# In Supervised Machine Learning, to perform regression on a set of data we want to define a cost function. Our goal is to\n",
    "# find the minimum of this cost function in order to find the best fit line.\n",
    "# Our cost function is J(w) = (1/2m) * [SUM from i=1 to m] [yhat(w) - y]^2\n",
    "def cost_function(m, errTerms):\n",
    "    # m is the number of input data points\n",
    "    # yhat is the best fit line estimate for a given value of slope, w\n",
    "    # y is the input data value for a given x\n",
    "    \n",
    "    # We assume that the vectors yhat and y have the correct number of entries\n",
    "    if errTerms.size != m:\n",
    "        print('The data array passed in to the cost function is not the correct size.')\n",
    "        exit()\n",
    "    \n",
    "    # Calculate a vector of the squares of the errors\n",
    "    sqErr = np.square(errTerms)\n",
    "    \n",
    "    # Sum all of the squared errors to get a scalar\n",
    "    sumErr = np.sum(sqErr)\n",
    "    \n",
    "    # Calculate the cost function\n",
    "    Jw = (1./(2.*m)) * sumErr\n",
    "    \n",
    "    return Jw\n",
    "\n",
    "# Both the cost function and its partial derivatives contain the same collection of terms, which we will compute a number\n",
    "# of times.\n",
    "# This collection of terms is yhat - y = wx + b - y\n",
    "def error_terms(y, w=None, x=None, b=None, yhat=None):\n",
    "    # y is a vector of y-coordinates of the input points that correspond to the given x-values\n",
    "    # w is the slope of the regression line\n",
    "    # x is a vector of x-coordinates of the input points\n",
    "    # b is the y-intercept of the regression line\n",
    "    # yhat is the equation for our regression line, wx+b\n",
    "    \n",
    "    # Check which form of yhat to use in our calculations\n",
    "    if yhat is None and (w is not None and x is not None and b is not None):\n",
    "        wx = np.multiply(w, x)\n",
    "        yhat = np.add(wx, b)\n",
    "    elif yhat is None and (w is None or x is None or b is None):\n",
    "        print('Error: The error_terms function is not receiving appropriate inputs.')\n",
    "        exit()\n",
    "    \n",
    "    termVec = np.add(yhat, -y)\n",
    "    \n",
    "    return termVec\n",
    "\n",
    "#####################\n",
    "##### MAIN CODE #####\n",
    "#####################\n",
    "\n",
    "# Initialize basic variables\n",
    "m = 5   # Number of input data points\n",
    "x = np.array([])   # Vector of independent variable data points\n",
    "y = np.array([])   # Vector of dependent variable data points\n",
    "boxSize = 10.   # Size of the box made by the data in the xy-plane\n",
    "w0 = 0.   # Initial value of the slope\n",
    "b0 = 0.   # Initial value of the y-intercept\n",
    "alpha = 0.01   # Learning rate\n",
    "errLim = 10.**(-6.)   # Error difference at which we consider the iterative regression to have converged\n",
    "\n",
    "# In the absence of real data, generate a series of random numbers\n",
    "for i in range(0, m):\n",
    "    x = np.append(x, boxSize*r.random())\n",
    "    y = np.append(y, boxSize*r.random())\n",
    "    \n",
    "# Find the indices where the sorted x values will end up and use it to also sort the y values\n",
    "xySort = x.argsort()\n",
    "x = x[xySort]\n",
    "y = y[xySort]\n",
    "\n",
    "# Make vectors of the different slope (w) and y-intercept (b) values that we will try\n",
    "# Our linear fit equation is y = wx + b\n",
    "w = np.array([w0])\n",
    "b = np.array([b0])\n",
    "\n",
    "# Compute the initial error and cost function\n",
    "errTerms = error_terms(y,w=w[0],x=x,b=b[0])\n",
    "err0 = cost_function(m,errTerms)\n",
    "err = np.array([err0])\n",
    "\n",
    "# Here we iterate following the gradient descent method.\n",
    "# The loop ends when the differenc\n",
    "i = 0   # Initialize a loop counter\n",
    "errOld = 1./errLim   # Make an arbitrarily large error to compare to on the first time step\n",
    "while np.abs(err[i]-errOld) > errLim:\n",
    "    # Calculate the updated slope and y-intercept values using the partial derivatives\n",
    "    wNew = w[i] - (alpha/m)*np.sum(np.multiply(x,errTerms))\n",
    "    bNew = b[i] - (alpha/m)*np.sum(errTerms)\n",
    "    \n",
    "    # Append our slope and intercept vectors with the new values\n",
    "    w = np.append(w,wNew)\n",
    "    b = np.append(b,bNew)\n",
    "    \n",
    "    # Compute the new error\n",
    "    i += 1   # Increment the loop counter\n",
    "    errTerms = error_terms(y,w=w[i],x=x,b=b[i])\n",
    "    errNew = cost_function(m,errTerms)\n",
    "    err = np.append(err,errNew)\n",
    "    \n",
    "    # Store the previous error in errOld for the while loop\n",
    "    errOld = err[i-1]\n",
    "\n",
    "# Make a matrix for our error values\n",
    "#err = np.zeros((len(w), len(b)))\n",
    "\n",
    "# For each one of our x-values,\n",
    "#for wInd in range(0, len(w)):\n",
    "    # and for every individual one of our potential slope values w,\n",
    "#    for bInd in range(0, len(b)):\n",
    "        # calculate the error corresponding to every potential y-intercept b.\n",
    "#        wx = np.multiply(w[wInd], x)\n",
    "#        yhat = np.add(wx, b[bInd])\n",
    "#        err[wInd][bInd] = cost_function(m,yhat,y)\n",
    "        \n",
    "# Minimize the error to find the best fit line\n",
    "#errMin = np.min(err)\n",
    "#wInd = np.where(err == errMin)[0][0]   # Matrix indices that correspond to the minimum error\n",
    "#bInd = np.where(err == errMin)[1][0]\n",
    "#wx = np.multiply(w[wInd],x)\n",
    "#yMin = np.add(wx,b[bInd])\n",
    "\n",
    "# Plot both the input data and the regression line\n",
    "plt.axis([0., boxSize, 0., boxSize])\n",
    "plt.plot(x, y, marker='o')\n",
    "plt.plot(x, np.add(errTerms,y), marker='*')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac1ecc6",
   "metadata": {},
   "source": [
    "The update steps for gradient descent in our linear regression model are given by\n",
    "\n",
    "\\begin{gather}\n",
    "    w_{new} = w - \\alpha \\frac{\\partial}{\\partial w} J(w,b) \\\\\n",
    "    b_{new} = b - \\alpha \\frac{\\partial}{\\partial b} J(w,b)\n",
    "\\end{gather}\n",
    "\n",
    "where $\\alpha$ is the learning rate. To compute this, we need to find the partial derivatives:\n",
    "\n",
    "\\begin{gather}\n",
    "    \\frac{\\partial}{\\partial w} J(w,b)\n",
    "    = \\frac{\\partial}{\\partial w} \\left[ \\frac{1}{2m} \\sum_{i=0}^m (\\hat{y}-y)^2 \\right]\n",
    "    = \\frac{\\partial}{\\partial w} \\left[ \\frac{1}{2m} \\sum_{i=0}^m (wx+b-y)^2 \\right]\n",
    "    = \\frac{1}{2m} \\sum_{i=0}^m \\left[ 2x(wx+b-y) \\right]\n",
    "    = \\frac{1}{m} \\sum_{i=0}^m  x(wx+b-y)\n",
    "    \\\\\n",
    "    \\frac{\\partial}{\\partial b} J(w,b)\n",
    "    = \\frac{\\partial}{\\partial b} \\left[ \\frac{1}{2m} \\sum_{i=0}^m (wx+b-y)^2 \\right]\n",
    "    = \\frac{1}{2m} \\sum_{i=0}^m \\left[ 2(wx+b-y) \\right]\n",
    "    = \\frac{1}{m} \\sum_{i=0}^m  (wx+b-y)\n",
    "\\end{gather}\n",
    "\n",
    "With this information, we can write our update steps as\n",
    "\n",
    "\\begin{gather}\n",
    "    w_{new} = w - \\frac{\\alpha}{m} \\sum_{i=0}^m  x(wx+b-y) \\\\\n",
    "    b_{new} = b - \\frac{\\alpha}{m} \\sum_{i=0}^m  (wx+b-y)\n",
    "\\end{gather}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b93b667",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
